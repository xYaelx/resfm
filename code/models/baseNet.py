import abc
import torch
from utils import geo_utils
from kornia.geometry.conversions import quaternion_to_rotation_matrix

class BaseNet(torch.nn.Module):
    def __init__(self, conf):
        super(BaseNet, self).__init__()

        self.calibrated = conf.get_bool('dataset.calibrated')
        self.normalize_output = conf.get_string('model.normalize_output', default=None)
        self.rot_representation = conf.get_string('model.rot_representation', default='quat')
        self.soft_sign = torch.nn.Softsign()

        if self.calibrated and self.rot_representation == '6d':
            print('rot representation: ' + self.rot_representation)
            self.out_channels = 9
        elif self.calibrated and self.rot_representation == 'quat':
            self.out_channels = 7
        elif self.calibrated and self.rot_representation == 'svd':
            self.out_channels = 12
        elif not self.calibrated:
            self.out_channels = 12
        else:
            print("Illegal output format")
            exit()

    @abc.abstractmethod
    def forward(self, data):
        pass

    def extract_model_outputs(self, x, pts_3D, data):
        # Get points
        pts_3D = geo_utils.ones_padding(pts_3D)

        # Get calibrated predictions
        if self.calibrated:
            # Get rotation
            if self.rot_representation == '6d':
                pass
            elif self.rot_representation == 'svd':
                m = x[:, :9].reshape(-1, 3, 3)
                RTs = geo_utils.project_to_rot(m)
            elif self.rot_representation == 'quat':
                RTs = quaternion_to_rotation_matrix(x[:, :4]) # wxyz format
            else:
                print("Illegal output format")
                exit()

            # Get translation
            minRTts = x[:, -3:]

            # Get camera matrix
            Ps = torch.cat((RTs, minRTts.unsqueeze(dim=-1)), dim=-1)


        # The model outputs a normalized camera! Meaning from world coordinates to camera coordinates, not to pixels in the image.
        # Ps_norm: [R | t]
        # pts_3D: world coordinates
        pred_cams = {"Ps_norm": Ps, "pts3D": pts_3D}
        return pred_cams

